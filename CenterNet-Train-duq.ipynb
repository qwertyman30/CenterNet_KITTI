{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3966abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/monish/anaconda3/envs/thesis/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from progress.bar import Bar\n",
    "import pycocotools.coco as coco\n",
    "import time\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision\n",
    "import torchvision.ops\n",
    "\n",
    "from dcn_v2 import DCN\n",
    "\n",
    "from decode import ddd_decode\n",
    "from debugger import Debugger\n",
    "from image import flip, color_aug\n",
    "from image import get_affine_transform, affine_transform\n",
    "from image import gaussian_radius, draw_umich_gaussian, draw_msra_gaussian\n",
    "from oracle_utils import gen_oracle_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4de077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.3\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seed = 317\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "BatchNorm = nn.BatchNorm2d\n",
    "BN_MOMENTUM = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "952562a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_url(data='imagenet', name='dla34', hash='ba72cf86'):\n",
    "    return os.path.join('http://dl.yf.io/dla/models', data, '{}-{}.pth'.format(name, hash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49291446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5564351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=dilation,\n",
    "                               bias=False, dilation=dilation)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=dilation,\n",
    "                               bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x, residual=None):\n",
    "        if residual is None:\n",
    "            residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f65e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        expansion = Bottleneck.expansion\n",
    "        bottle_planes = planes // expansion\n",
    "        self.conv1 = nn.Conv2d(inplanes, bottle_planes,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(bottle_planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(bottle_planes, bottle_planes, kernel_size=3,\n",
    "                               stride=stride, padding=dilation,\n",
    "                               bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(bottle_planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(bottle_planes, planes,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x, residual=None):\n",
    "        if residual is None:\n",
    "            residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05eed0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckX(nn.Module):\n",
    "    expansion = 2\n",
    "    cardinality = 32\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
    "        super(BottleneckX, self).__init__()\n",
    "        cardinality = BottleneckX.cardinality\n",
    "        # dim = int(math.floor(planes * (BottleneckV5.expansion / 64.0)))\n",
    "        # bottle_planes = dim * cardinality\n",
    "        bottle_planes = planes * cardinality // 32\n",
    "        self.conv1 = nn.Conv2d(inplanes, bottle_planes,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(bottle_planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(bottle_planes, bottle_planes, kernel_size=3,\n",
    "                               stride=stride, padding=dilation, bias=False,\n",
    "                               dilation=dilation, groups=cardinality)\n",
    "        self.bn2 = nn.BatchNorm2d(bottle_planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(bottle_planes, planes,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x, residual=None):\n",
    "        if residual is None:\n",
    "            residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313ccd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Root(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, residual):\n",
    "        super(Root, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, 1,\n",
    "            stride=1, bias=False, padding=(kernel_size - 1) // 2)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(self, *x):\n",
    "        children = x\n",
    "        x = self.conv(torch.cat(x, 1))\n",
    "        x = self.bn(x)\n",
    "        if self.residual:\n",
    "            x += children[0]\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdd048f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(nn.Module):\n",
    "    def __init__(self, levels, block, in_channels, out_channels, stride=1,\n",
    "                 level_root=False, root_dim=0, root_kernel_size=1,\n",
    "                 dilation=1, root_residual=False):\n",
    "        super(Tree, self).__init__()\n",
    "        if root_dim == 0:\n",
    "            root_dim = 2 * out_channels\n",
    "        if level_root:\n",
    "            root_dim += in_channels\n",
    "        if levels == 1:\n",
    "            self.tree1 = block(in_channels, out_channels, stride,\n",
    "                               dilation=dilation)\n",
    "            self.tree2 = block(out_channels, out_channels, 1,\n",
    "                               dilation=dilation)\n",
    "        else:\n",
    "            self.tree1 = Tree(levels - 1, block, in_channels, out_channels,\n",
    "                              stride, root_dim=0,\n",
    "                              root_kernel_size=root_kernel_size,\n",
    "                              dilation=dilation, root_residual=root_residual)\n",
    "            self.tree2 = Tree(levels - 1, block, out_channels, out_channels,\n",
    "                              root_dim=root_dim + out_channels,\n",
    "                              root_kernel_size=root_kernel_size,\n",
    "                              dilation=dilation, root_residual=root_residual)\n",
    "        if levels == 1:\n",
    "            self.root = Root(root_dim, out_channels, root_kernel_size,\n",
    "                             root_residual)\n",
    "        self.level_root = level_root\n",
    "        self.root_dim = root_dim\n",
    "        self.downsample = None\n",
    "        self.project = None\n",
    "        self.levels = levels\n",
    "        if stride > 1:\n",
    "            self.downsample = nn.MaxPool2d(stride, stride=stride)\n",
    "        if in_channels != out_channels:\n",
    "            self.project = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels,\n",
    "                          kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels, momentum=BN_MOMENTUM)\n",
    "            )\n",
    "\n",
    "    def forward(self, x, residual=None, children=None):\n",
    "        children = [] if children is None else children\n",
    "        bottom = self.downsample(x) if self.downsample else x\n",
    "        residual = self.project(bottom) if self.project else bottom\n",
    "        if self.level_root:\n",
    "            children.append(bottom)\n",
    "        x1 = self.tree1(x, residual)\n",
    "        if self.levels == 1:\n",
    "            x2 = self.tree2(x1)\n",
    "            x = self.root(x2, x1, *children)\n",
    "        else:\n",
    "            children.append(x1)\n",
    "            x = self.tree2(x1, children=children)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3194ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLA(nn.Module):\n",
    "    def __init__(self, levels, channels, num_classes=1000,\n",
    "                 block=BasicBlock, residual_root=False, linear_root=False):\n",
    "        super(DLA, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.num_classes = num_classes\n",
    "        self.base_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, channels[0], kernel_size=7, stride=1,\n",
    "                      padding=3, bias=False),\n",
    "            nn.BatchNorm2d(channels[0], momentum=BN_MOMENTUM),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.level0 = self._make_conv_level(\n",
    "            channels[0], channels[0], levels[0])\n",
    "        self.level1 = self._make_conv_level(\n",
    "            channels[0], channels[1], levels[1], stride=2)\n",
    "        self.level2 = Tree(levels[2], block, channels[1], channels[2], 2,\n",
    "                           level_root=False, root_residual=residual_root)\n",
    "        self.level3 = Tree(levels[3], block, channels[2], channels[3], 2,\n",
    "                           level_root=True, root_residual=residual_root)\n",
    "        self.level4 = Tree(levels[4], block, channels[3], channels[4], 2,\n",
    "                           level_root=True, root_residual=residual_root)\n",
    "        self.level5 = Tree(levels[5], block, channels[4], channels[5], 2,\n",
    "                           level_root=True, root_residual=residual_root)\n",
    "\n",
    "    def _make_level(self, block, inplanes, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or inplanes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.MaxPool2d(stride, stride=stride),\n",
    "                nn.Conv2d(inplanes, planes,\n",
    "                          kernel_size=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(planes, momentum=BN_MOMENTUM),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(inplanes, planes, stride, downsample=downsample))\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_conv_level(self, inplanes, planes, convs, stride=1, dilation=1):\n",
    "        modules = []\n",
    "        for i in range(convs):\n",
    "            modules.extend([\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=3,\n",
    "                          stride=stride if i == 0 else 1,\n",
    "                          padding=dilation, bias=False, dilation=dilation),\n",
    "                nn.BatchNorm2d(planes, momentum=BN_MOMENTUM),\n",
    "                nn.ReLU(inplace=True)])\n",
    "            inplanes = planes\n",
    "        return nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        x = self.base_layer(x)\n",
    "        for i in range(6):\n",
    "            x = getattr(self, 'level{}'.format(i))(x)\n",
    "            y.append(x)\n",
    "        return y\n",
    "\n",
    "    def load_pretrained_model(self, data='imagenet', name='dla34', hash='ba72cf86'):\n",
    "        # fc = self.fc\n",
    "        if name.endswith('.pth'):\n",
    "            model_weights = torch.load(data + name)\n",
    "        else:\n",
    "            model_url = get_model_url(data, name, hash)\n",
    "            model_weights = model_zoo.load_url(model_url)\n",
    "        num_classes = len(model_weights[list(model_weights.keys())[-1]])\n",
    "        self.fc = nn.Conv2d(\n",
    "            self.channels[-1], num_classes,\n",
    "            kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.load_state_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714c9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dla34(pretrained=True, **kwargs):  # DLA-34\n",
    "    model = DLA([1, 1, 1, 2, 2, 1],\n",
    "                [16, 32, 64, 128, 256, 512],\n",
    "                block=BasicBlock, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_pretrained_model(data='imagenet', name='dla34', hash='ba72cf86')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10ea4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bn(bn):\n",
    "    global BatchNorm\n",
    "    BatchNorm = bn\n",
    "    dla.BatchNorm = bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa436122",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "374581cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_fc_weights(layers):\n",
    "    for m in layers.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4d83472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_up_weights(up):\n",
    "    w = up.weight.data\n",
    "    f = math.ceil(w.size(2) / 2)\n",
    "    c = (2 * f - 1 - f % 2) / (2. * f)\n",
    "    for i in range(w.size(2)):\n",
    "        for j in range(w.size(3)):\n",
    "            w[0, 0, i, j] = \\\n",
    "                (1 - math.fabs(i / f - c)) * (1 - math.fabs(j / f - c))\n",
    "    for c in range(1, w.size(0)):\n",
    "        w[c, 0, :, :] = w[0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f18721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeformConv(nn.Module):\n",
    "    def __init__(self, chi, cho):\n",
    "        super(DeformConv, self).__init__()\n",
    "        self.actf = nn.Sequential(\n",
    "            nn.BatchNorm2d(cho, momentum=BN_MOMENTUM),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv = DCN(chi, cho, kernel_size=(3,3), stride=1, padding=1, dilation=1, deformable_groups=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.actf(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cab51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDAUp(nn.Module):\n",
    "\n",
    "    def __init__(self, o, channels, up_f):\n",
    "        super(IDAUp, self).__init__()\n",
    "        for i in range(1, len(channels)):\n",
    "            c = channels[i]\n",
    "            f = int(up_f[i])  \n",
    "            proj = DeformConv(c, o)\n",
    "            node = DeformConv(o, o)\n",
    "     \n",
    "            up = nn.ConvTranspose2d(o, o, f * 2, stride=f, \n",
    "                                    padding=f // 2, output_padding=0,\n",
    "                                    groups=o, bias=False)\n",
    "            fill_up_weights(up)\n",
    "\n",
    "            setattr(self, 'proj_' + str(i), proj)\n",
    "            setattr(self, 'up_' + str(i), up)\n",
    "            setattr(self, 'node_' + str(i), node)\n",
    "                 \n",
    "        \n",
    "    def forward(self, layers, startp, endp):\n",
    "        for i in range(startp + 1, endp):\n",
    "            upsample = getattr(self, 'up_' + str(i - startp))\n",
    "            project = getattr(self, 'proj_' + str(i - startp))\n",
    "            layers[i] = upsample(project(layers[i]))\n",
    "            node = getattr(self, 'node_' + str(i - startp))\n",
    "            layers[i] = node(layers[i] + layers[i - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe2e7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLAUp(nn.Module):\n",
    "    def __init__(self, startp, channels, scales, in_channels=None):\n",
    "        super(DLAUp, self).__init__()\n",
    "        self.startp = startp\n",
    "        if in_channels is None:\n",
    "            in_channels = channels\n",
    "        self.channels = channels\n",
    "        channels = list(channels)\n",
    "        scales = np.array(scales, dtype=int)\n",
    "        for i in range(len(channels) - 1):\n",
    "            j = -i - 2\n",
    "            setattr(self, 'ida_{}'.format(i),\n",
    "                    IDAUp(channels[j], in_channels[j:],\n",
    "                          scales[j:] // scales[j]))\n",
    "            scales[j + 1:] = scales[j]\n",
    "            in_channels[j + 1:] = [channels[j] for _ in channels[j + 1:]]\n",
    "\n",
    "    def forward(self, layers):\n",
    "        out = [layers[-1]] # start with 32\n",
    "        for i in range(len(layers) - self.startp - 1):\n",
    "            ida = getattr(self, 'ida_{}'.format(i))\n",
    "            ida(layers, len(layers) -i - 2, len(layers))\n",
    "            out.insert(0, layers[-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4882df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLASeg(nn.Module):\n",
    "    def __init__(self, heads, down_ratio, final_kernel,\n",
    "                 last_level, head_conv, out_channel=0, pretrained=False):\n",
    "        super(DLASeg, self).__init__()\n",
    "        assert down_ratio in [2, 4, 8, 16]\n",
    "        self.first_level = int(np.log2(down_ratio))\n",
    "        self.last_level = last_level\n",
    "        self.base = dla34(pretrained=pretrained)\n",
    "        channels = self.base.channels\n",
    "        scales = [2 ** i for i in range(len(channels[self.first_level:]))]\n",
    "        self.dla_up = DLAUp(self.first_level, channels[self.first_level:], scales)\n",
    "\n",
    "        if out_channel == 0:\n",
    "            out_channel = channels[self.first_level]\n",
    "\n",
    "        self.ida_up = IDAUp(out_channel, channels[self.first_level:self.last_level], \n",
    "                            [2 ** i for i in range(self.last_level - self.first_level)])\n",
    "        \n",
    "        self.heads = heads\n",
    "                \n",
    "        for head in self.heads:\n",
    "            classes = self.heads[head]\n",
    "            if head_conv > 0:\n",
    "                fc = nn.Sequential(\n",
    "                    nn.Conv2d(channels[self.first_level], head_conv,\n",
    "                              kernel_size=3, padding=1, bias=True),\n",
    "                    nn.ReLU(inplace=True),\n",
    "                    nn.Conv2d(head_conv, classes, \n",
    "                              kernel_size=final_kernel, stride=1, \n",
    "                              padding=final_kernel // 2, bias=True))\n",
    "                if 'hm' in head:\n",
    "                    fc[-1].bias.data.fill_(-2.19)\n",
    "                else:\n",
    "                    fill_fc_weights(fc)\n",
    "            else:\n",
    "                fc = nn.Conv2d(channels[self.first_level], classes, \n",
    "                               kernel_size=final_kernel, stride=1, \n",
    "                               padding=final_kernel // 2, bias=True)\n",
    "                if 'hm' in head:\n",
    "                    fc.bias.data.fill_(-2.19)\n",
    "                else:\n",
    "                    fill_fc_weights(fc)\n",
    "            self.__setattr__(head, fc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.dla_up(x)\n",
    "\n",
    "        y = []\n",
    "        for i in range(self.last_level - self.first_level):\n",
    "            y.append(x[i].clone())\n",
    "        self.ida_up(y, 0, len(y))\n",
    "\n",
    "        z = {}\n",
    "        for head in self.heads:\n",
    "            z[head] = self.__getattr__(head)(y[-1])\n",
    "        return [z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e485964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DUQ(nn.Module):\n",
    "    def __init__(self,\n",
    "                 opt,\n",
    "                 centroid_size=512,\n",
    "                 num_classes=3,\n",
    "                 width=96,\n",
    "                 height=320,\n",
    "                 length_scale=0.25,\n",
    "                 gamma=0.9,\n",
    "                 center_pixel_weighting=20,\n",
    "                 cuda=True):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = DLASeg(opt[\"heads\"],\n",
    "                                        final_kernel=1,\n",
    "                                        last_level=5,\n",
    "                                        head_conv=opt[\"head_conv\"],\n",
    "                                        down_ratio=opt[\"down_ratio\"],\n",
    "                                        pretrained=True)\n",
    "        self.centroid_size = centroid_size\n",
    "        self.num_classes = num_classes\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # CENTROID_SIZE x NUM_CLASSES x MODEL_OUTPUT\n",
    "        # MODEL_OUTPUT (NUM_CLASSES x WIDTH x HEIGHT)\n",
    "        self.W = nn.Parameter(torch.zeros(centroid_size, num_classes, num_classes, width, height))\n",
    "        nn.init.kaiming_normal_(self.W, nonlinearity=\"relu\")\n",
    "        \n",
    "        self.N = torch.zeros(num_classes, width, height) + 13\n",
    "        self.M = torch.normal(torch.zeros(centroid_size, num_classes, width, height), 0.05)\n",
    "        if cuda:\n",
    "            self.feature_extractor = self.feature_extractor.cuda()\n",
    "            self.N = self.N.cuda()\n",
    "            self.M = self.M.cuda()\n",
    "        \n",
    "        self.M = self.N * self.M\n",
    "\n",
    "        self.sigma = length_scale\n",
    "        self.center_pixel_weighting = center_pixel_weighting\n",
    "        \n",
    "    def freeze_feature_extractor(self):\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Length scale annealing\n",
    "    def update_sigma(self):\n",
    "        self.sigma = max(0.05, 0.999*self.sigma)\n",
    "\n",
    "    # Centroid momentum scheduling\n",
    "    def update_gamma(self, epoch):\n",
    "        if epoch == 5:\n",
    "            self.gamma = 0.99\n",
    "        elif epoch == 20:\n",
    "            self.gamma = 0.999\n",
    "        elif epoch == 60:\n",
    "            self.gamma = 0.9999\n",
    "\n",
    "    def update_embeddings(self, x, y):\n",
    "        self.N = self.gamma * self.N + (1 - self.gamma) * (y ** self.center_pixel_weighting).sum(0)\n",
    "\n",
    "        z = self.feature_extractor(x)\n",
    "        z = z[0]['hm']\n",
    "\n",
    "        # b->batch_size, w->width, h->height\n",
    "        # c->centroid_size, n->num_classes\n",
    "        z = torch.einsum(\"bnwh,cnnwh->bcnwh\", z, self.W)\n",
    "        # torch.conv2d(z, W, stride=[1, 1], padding='valid', dilation=[1, 1])\n",
    "        embedding_sum = torch.einsum(\"bcnwh,bnwh->cnwh\", z, y ** self.center_pixel_weighting)\n",
    "        embedding_sum = embedding_sum / torch.sum(y ** self.center_pixel_weighting)\n",
    "\n",
    "        # Balanced centroid update\n",
    "        self.M = self.gamma * self.M + (1 - self.gamma) * embedding_sum\n",
    "\n",
    "    def rbf(self, z):\n",
    "        # b->batch_size, w->width, h->height\n",
    "        # c->centroid_size, n->num_classes\n",
    "        z = torch.einsum(\"bnwh,cnnwh->bcnwh\", z, self.W)\n",
    "        # torch.conv2d(z, W, stride=[1, 1], padding='valid', dilation=[1, 1])\n",
    "\n",
    "        # centroids\n",
    "        self.embeddings = self.M / self.N\n",
    "\n",
    "        # square of l2 distance between predictions and centroids\n",
    "        diff = ((z - self.embeddings)**2)\n",
    "\n",
    "        # outlier protection\n",
    "        diff = torch.clip(diff, min=-3*self.sigma, max=3*self.sigma)\n",
    "        \n",
    "        # RBF function\n",
    "        rbf = diff.mean(1).div(2 * self.sigma ** 2).mul(-1).exp()\n",
    "\n",
    "        return z, rbf\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.feature_extractor(x)\n",
    "        hm = feat[0]['hm']\n",
    "        z, y_pred = self.rbf(hm)\n",
    "\n",
    "        feat[0]['hm'] = y_pred.clone()\n",
    "        # z is used for l2 regularization of hyperspace\n",
    "        return z, feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67357cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _neg_loss(pred, gt):\n",
    "    ''' Modified focal loss. Exactly the same as CornerNet.\n",
    "        Runs faster and costs a little bit more memory\n",
    "        Arguments:\n",
    "          pred (batch x c x h x w)\n",
    "          gt_regr (batch x c x h x w)\n",
    "    '''\n",
    "    pos_inds = gt.eq(1).float()\n",
    "    neg_inds = gt.lt(1).float()\n",
    "    \n",
    "    neg_weights = torch.pow(1 - gt, 4)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    pos_loss = torch.log(pred) * torch.pow(1 - pred, 2) * pos_inds\n",
    "    neg_loss = torch.log(1 - pred) * torch.pow(pred, 2) * neg_weights * neg_inds\n",
    "    \n",
    "    num_pos  = pos_inds.float().sum()\n",
    "    pos_loss = pos_loss.sum()\n",
    "    neg_loss = neg_loss.sum()\n",
    "    \n",
    "    if num_pos == 0:\n",
    "        loss = loss - neg_loss\n",
    "    else:\n",
    "        loss = loss - (pos_loss + neg_loss) / num_pos\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed596def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gather_feat(feat, ind, mask=None):\n",
    "    dim  = feat.size(2)\n",
    "    ind  = ind.unsqueeze(2).expand(ind.size(0), ind.size(1), dim)\n",
    "    feat = feat.gather(1, ind)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(2).expand_as(feat)\n",
    "        feat = feat[mask]\n",
    "        feat = feat.view(-1, dim)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c091a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transpose_and_gather_feat(feat, ind):\n",
    "    feat = feat.permute(0, 2, 3, 1).contiguous()\n",
    "    feat = feat.view(feat.size(0), -1, feat.size(3))\n",
    "    feat = _gather_feat(feat, ind)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dc90831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(L1Loss, self).__init__()\n",
    "  \n",
    "    def forward(self, output, mask, ind, target):\n",
    "        pred = _transpose_and_gather_feat(output, ind)\n",
    "        mask = mask.unsqueeze(2).expand_as(pred).float()\n",
    "        loss = F.l1_loss(pred * mask, target * mask, reduction='mean')\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cf9a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rot_loss(output, target_bin, target_res, mask):\n",
    "    output = output.view(-1, 8)\n",
    "    target_bin = target_bin.view(-1, 2)\n",
    "    target_res = target_res.view(-1, 2)\n",
    "    mask = mask.view(-1, 1)\n",
    "    loss_bin1 = compute_bin_loss(output[:, 0:2], target_bin[:, 0], mask)\n",
    "    loss_bin2 = compute_bin_loss(output[:, 4:6], target_bin[:, 1], mask)\n",
    "    loss_res = torch.zeros_like(loss_bin1)\n",
    "    if target_bin[:, 0].nonzero().shape[0] > 0:\n",
    "        idx1 = target_bin[:, 0].nonzero()[:, 0]\n",
    "        valid_output1 = torch.index_select(output, 0, idx1.long())\n",
    "        valid_target_res1 = torch.index_select(target_res, 0, idx1.long())\n",
    "        loss_sin1 = compute_res_loss(\n",
    "          valid_output1[:, 2], torch.sin(valid_target_res1[:, 0]))\n",
    "        loss_cos1 = compute_res_loss(\n",
    "          valid_output1[:, 3], torch.cos(valid_target_res1[:, 0]))\n",
    "        loss_res += loss_sin1 + loss_cos1\n",
    "    if target_bin[:, 1].nonzero().shape[0] > 0:\n",
    "        idx2 = target_bin[:, 1].nonzero()[:, 0]\n",
    "        valid_output2 = torch.index_select(output, 0, idx2.long())\n",
    "        valid_target_res2 = torch.index_select(target_res, 0, idx2.long())\n",
    "        loss_sin2 = compute_res_loss(\n",
    "          valid_output2[:, 6], torch.sin(valid_target_res2[:, 1]))\n",
    "        loss_cos2 = compute_res_loss(\n",
    "          valid_output2[:, 7], torch.cos(valid_target_res2[:, 1]))\n",
    "        loss_res += loss_sin2 + loss_cos2\n",
    "    return loss_bin1 + loss_bin2 + loss_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b0b37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_res_loss(output, target):\n",
    "    return F.smooth_l1_loss(output, target, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "927bd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: weight\n",
    "def compute_bin_loss(output, target, mask):\n",
    "    mask = mask.expand_as(output)\n",
    "    output = output * mask.float()\n",
    "    return F.cross_entropy(output, target, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecfd5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinRotLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinRotLoss, self).__init__()\n",
    "  \n",
    "    def forward(self, output, mask, ind, rotbin, rotres):\n",
    "        pred = _transpose_and_gather_feat(output, ind)\n",
    "        loss = compute_rot_loss(pred, rotbin, rotres, mask)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0dd233e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    '''nn.Module warpper for focal loss'''\n",
    "    def __init__(self):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.neg_loss = _neg_loss\n",
    "\n",
    "    def forward(self, out, target):\n",
    "        return self.neg_loss(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2250f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperspace regularization\n",
    "def loss_hyperspace(y, z, embeddings, center_pixel_weighting=20):\n",
    "    norm = torch.dist(z, embeddings, p=2) ** 2\n",
    "    loss = torch.sum(norm * (y ** center_pixel_weighting))\n",
    "    weight = torch.sum(y ** center_pixel_weighting)\n",
    "    \n",
    "    loss = torch.sum(loss) / weight\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "433d012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(x):\n",
    "    y = torch.clamp(x.sigmoid_(), min=1e-4, max=1-1e-4)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24a3efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Duq_with_centernet_loss(torch.nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(Duq_with_centernet_loss, self).__init__()\n",
    "        self.crit = FocalLoss()\n",
    "        self.crit_reg = L1Loss()\n",
    "        self.crit_rot = BinRotLoss()\n",
    "        self.hyperspace = loss_hyperspace\n",
    "        self.opt = opt\n",
    "\n",
    "    def forward(self, duq, batch, embeddings):\n",
    "        opt = self.opt\n",
    "        \n",
    "        hm_loss, dep_loss, rot_loss, dim_loss = 0, 0, 0, 0\n",
    "        wh_loss, off_loss = 0, 0\n",
    "        hyp_loss = 0\n",
    "        z, outputs = duq\n",
    "        for s in range(opt[\"num_stacks\"]):\n",
    "            output = outputs[s]\n",
    "            output['hm'] = _sigmoid(output['hm'])\n",
    "            output['dep'] = 1. / (output['dep'].sigmoid() + 1e-6) - 1.\n",
    "            \n",
    "            if opt[\"eval_oracle_dep\"]:\n",
    "                output['dep'] = torch.from_numpy(gen_oracle_map(\n",
    "                    batch['dep'].detach().cpu().numpy(), \n",
    "                    batch['ind'].detach().cpu().numpy(), \n",
    "                    opt[\"output_w\"], opt[\"output_h\"])).to(opt[\"device\"])\n",
    "            \n",
    "            hm_loss += self.crit(output['hm'], batch['hm']) / opt[\"num_stacks\"]\n",
    "            hyp_loss += self.hyperspace(output['hm'],\n",
    "                                        z,\n",
    "                                        embeddings,\n",
    "                                        opt[\"center_pixel_weighting\"])  / opt[\"num_stacks\"]\n",
    "            \n",
    "            if opt[\"dep_weight\"] > 0:\n",
    "                dep_loss += self.crit_reg(output['dep'], batch['reg_mask'],\n",
    "                                          batch['ind'], batch['dep']) / opt[\"num_stacks\"]\n",
    "                \n",
    "            if opt[\"dim_weight\"] > 0:\n",
    "                dim_loss += self.crit_reg(output['dim'], batch['reg_mask'],\n",
    "                                          batch['ind'], batch['dim']) / opt[\"num_stacks\"]\n",
    "            \n",
    "            if opt[\"rot_weight\"] > 0:\n",
    "                rot_loss += self.crit_rot(output['rot'], batch['rot_mask'],\n",
    "                                          batch['ind'], batch['rotbin'],\n",
    "                                          batch['rotres']) / opt[\"num_stacks\"]\n",
    "\n",
    "            if opt[\"reg_bbox\"] and opt[\"wh_weight\"] > 0:\n",
    "                wh_loss += self.crit_reg(output['wh'], batch['rot_mask'],\n",
    "                                         batch['ind'], batch['wh']) / opt[\"num_stacks\"]\n",
    "\n",
    "            if opt[\"reg_offset\"] and opt[\"off_weight\"] > 0:\n",
    "                off_loss += self.crit_reg(output['reg'], batch['rot_mask'],\n",
    "                                          batch['ind'], batch['reg']) / opt[\"num_stacks\"]\n",
    "                \n",
    "        loss = opt[\"hm_weight\"] * hm_loss + opt[\"dep_weight\"] * dep_loss + \\\n",
    "                opt[\"dim_weight\"] * dim_loss + opt[\"rot_weight\"] * rot_loss +\\\n",
    "                opt[\"wh_weight\"] * wh_loss + opt[\"off_weight\"] * off_loss +\\\n",
    "                opt[\"hyp_weight\"] * hyp_loss\n",
    "\n",
    "        loss_stats = {'loss': loss, 'hm_loss': hm_loss, 'dep_loss': dep_loss, \n",
    "                      'dim_loss': dim_loss, 'rot_loss': rot_loss, 'wh_loss': wh_loss,\n",
    "                      'off_loss': off_loss, 'hyp_loss': hyp_loss}\n",
    "\n",
    "        return loss, loss_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4918edff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithLoss(torch.nn.Module):\n",
    "    def __init__(self, model, loss):\n",
    "        super(ModelWithLoss, self).__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "  \n",
    "    def forward(self, batch):\n",
    "        outputs = self.model(batch['input'])\n",
    "        loss, loss_stats = self.loss(outputs, batch)\n",
    "        return outputs[-1], loss, loss_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b89b89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        if self.count > 0:\n",
    "            self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95b45f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTrainer(object):\n",
    "    def __init__(self, opt, model, optimizer=None):\n",
    "        self.opt = opt\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_stats, self.loss = self._get_losses(opt)\n",
    "        self.model_with_loss = ModelWithLoss(model, self.loss).to(device=opt[\"device\"])\n",
    "\n",
    "    def set_device(self, device):\n",
    "        self.model_with_loss = self.model_with_loss.to(device)\n",
    "    \n",
    "        for state in self.optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(device=device, non_blocking=True)\n",
    "\n",
    "    def run_epoch(self, phase, epoch, data_loader):\n",
    "        model_with_loss = self.model_with_loss\n",
    "        if phase == 'train':\n",
    "            model_with_loss.train()\n",
    "        else:\n",
    "            model_with_loss.eval()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        opt = self.opt\n",
    "        results = {}\n",
    "        data_time, batch_time = AverageMeter(), AverageMeter()\n",
    "        avg_loss_stats = {l: AverageMeter() for l in self.loss_stats}\n",
    "        num_iters = len(data_loader) if opt[\"num_iters\"] < 0 else opt[\"num_iters\"]\n",
    "        bar = Bar('{}/{}'.format(opt[\"task\"], opt[\"exp_id\"]), max=num_iters)\n",
    "        end = time.time()\n",
    "        for iter_id, batch in enumerate(data_loader):\n",
    "            if iter_id >= num_iters:\n",
    "                break\n",
    "            data_time.update(time.time() - end)\n",
    "        \n",
    "            for k in batch:\n",
    "                if k != 'meta':\n",
    "                    batch[k] = batch[k].to(device=opt[\"device\"], non_blocking=True)\n",
    "            output, loss, loss_stats = model_with_loss(batch)\n",
    "            loss = loss.mean()\n",
    "            \n",
    "            if phase == 'train':\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            Bar.suffix = '{phase}: [{0}][{1}/{2}]|Tot: {total:} |ETA: {eta:} '.format(\n",
    "                epoch, iter_id, num_iters, phase=phase,\n",
    "                total=bar.elapsed_td, eta=bar.eta_td)\n",
    "        \n",
    "            for l in avg_loss_stats:\n",
    "                avg_loss_stats[l].update(loss_stats[l].mean().item(), batch['input'].size(0))\n",
    "                Bar.suffix = Bar.suffix + '|{} {:.4f} '.format(l, avg_loss_stats[l].avg)\n",
    "            if not opt[\"hide_data_time\"]:\n",
    "                Bar.suffix = Bar.suffix + '|Data {dt.val:.3f}s({dt.avg:.3f}s) '\\\n",
    "                '|Net {bt.avg:.3f}s'.format(dt=data_time, bt=batch_time)\n",
    "            if opt[\"print_iter\"] > 0:\n",
    "                if iter_id % opt[\"print_iter\"] == 0:\n",
    "                    print('{}/{}| {}'.format(opt[\"task\"], opt[\"exp_id\"], Bar.suffix))\n",
    "            else:\n",
    "                bar.next()\n",
    "\n",
    "#             if opt[\"debug\"] > 0:\n",
    "#                 self.debug(batch, output, iter_id)\n",
    "\n",
    "#             if opt[\"test\"]:\n",
    "#                 self.save_result(output, batch, results)\n",
    "\n",
    "            del output, loss, loss_stats\n",
    "            \n",
    "        bar.finish()\n",
    "        ret = {k: v.avg for k, v in avg_loss_stats.items()}\n",
    "        ret['time'] = bar.elapsed_td.total_seconds() / 60.\n",
    "        return ret, results\n",
    "    \n",
    "    def debug(self, batch, output, iter_id):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save_result(self, output, batch, results):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _get_losses(self, opt):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def val(self, epoch, data_loader):\n",
    "        return self.run_epoch('val', epoch, data_loader)\n",
    "    \n",
    "    def train(self, epoch, data_loader):\n",
    "        return self.run_epoch('train', epoch, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "059cc7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DddTrainer(BaseTrainer):\n",
    "    def __init__(self, opt, model, optimizer=None):\n",
    "        super(DddTrainer, self).__init__(opt, model, optimizer=optimizer)\n",
    "        \n",
    "    def _get_losses(self, opt):\n",
    "        loss_states = ['loss', 'hm_loss', 'dep_loss', 'dim_loss',\n",
    "                       'rot_loss', 'wh_loss', 'off_loss']\n",
    "        loss = DddLoss(opt)\n",
    "        return loss_states, loss\n",
    "\n",
    "    def debug(self, batch, output, iter_id):\n",
    "        opt = self.opt\n",
    "        wh = output['wh'] if opt[\"reg_bbox\"] else None\n",
    "        reg = output['reg'] if opt[\"reg_offset\"] else None\n",
    "        dets = ddd_decode(output['hm'], output['rot'], output['dep'],\n",
    "                          output['dim'], wh=wh, reg=reg, K=opt[\"K\"])\n",
    "        \n",
    "        dets = dets.detach().cpu().numpy().reshape(1, -1, dets.shape[2])\n",
    "        calib = batch['meta']['calib'].detach().numpy()\n",
    "        \n",
    "        dets_pred = ddd_post_process(dets.copy(), batch['meta']['c'].detach().numpy(), \n",
    "                                     batch['meta']['s'].detach().numpy(), calib, opt)\n",
    "        dets_gt = ddd_post_process(batch['meta']['gt_det'].detach().numpy().copy(),\n",
    "                                   batch['meta']['c'].detach().numpy(), \n",
    "                                   batch['meta']['s'].detach().numpy(), calib, opt)\n",
    "        \n",
    "        #for i in range(input.size(0)):\n",
    "        for i in range(1):\n",
    "            debugger = Debugger(dataset=opt[\"dataset\"], ipynb=(opt[\"debug\"]==3),\n",
    "                                theme=opt[\"debugger_theme\"])\n",
    "            img = batch['input'][i].detach().cpu().numpy().transpose(1, 2, 0)\n",
    "            img = ((img * self.opt[\"std\"] + self.opt[\"mean\"]) * 255.).astype(np.uint8)\n",
    "            pred = debugger.gen_colormap(output['hm'][i].detach().cpu().numpy())\n",
    "            gt = debugger.gen_colormap(batch['hm'][i].detach().cpu().numpy())\n",
    "            debugger.add_blend_img(img, pred, 'hm_pred')\n",
    "            debugger.add_blend_img(img, gt, 'hm_gt')\n",
    "            debugger.add_ct_detection(img, dets[i], show_box=opt[\"reg_bbox\"],\n",
    "                                      center_thresh=opt[\"center_thresh\"], img_id='det_pred')\n",
    "            debugger.add_ct_detection(img, batch['meta']['gt_det'][i].cpu().numpy().copy(), \n",
    "                                      show_box=opt[\"reg_bbox\"], img_id='det_gt')\n",
    "            debugger.add_3d_detection(batch['meta']['image_path'][i], dets_pred[i], calib[i],\n",
    "                                      center_thresh=opt[\"center_thresh\"], img_id='add_pred')\n",
    "            debugger.add_3d_detection(batch['meta']['image_path'][i], dets_gt[i], calib[i],\n",
    "                                      center_thresh=opt[\"center_thresh\"], img_id='add_gt')\n",
    "            debugger.add_bird_views(dets_pred[i], dets_gt[i],\n",
    "                                    center_thresh=opt[\"center_thresh\"], img_id='bird_pred_gt')\n",
    "            debugger.compose_vis_add(batch['meta']['image_path'][i], dets_pred[i], calib[i],\n",
    "                                     opt[\"center_thresh\"], pred, 'bird_pred_gt', img_id='out')\n",
    "            if opt[\"debug\"] == 4:\n",
    "                debugger.save_all_imgs(opt[\"debug_dir\"], prefix='{}'.format(iter_id))\n",
    "            else:\n",
    "                debugger.show_all_imgs(pause=True)\n",
    "    \n",
    "    def save_result(self, output, batch, results):\n",
    "        opt = self.opt\n",
    "        wh = output['wh'] if opt[\"reg_bbox\"] else None\n",
    "        reg = output['reg'] if opt[\"reg_offset\"] else None\n",
    "        dets = ddd_decode(output['hm'], output['rot'], output['dep'],\n",
    "                          output['dim'], wh=wh, reg=reg, K=opt[\"K\"])\n",
    "        dets = dets.detach().cpu().numpy().reshape(1, -1, dets.shape[2])\n",
    "        calib = batch['meta']['calib'].detach().numpy()\n",
    "        dets_pred = ddd_post_process(dets.copy(), batch['meta']['c'].detach().numpy(),\n",
    "                                     batch['meta']['s'].detach().numpy(), calib, opt)\n",
    "        img_id = batch['meta']['img_id'].detach().numpy()[0]\n",
    "        results[img_id] = dets_pred[0]\n",
    "        for j in range(1, opt[\"num_classes\"] + 1):\n",
    "            keep_inds = (results[img_id][j][:, -1] > opt[\"center_thresh\"])\n",
    "            results[img_id][j] = results[img_id][j][keep_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e22ab49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KITTI(data.Dataset):\n",
    "    num_classes = 3\n",
    "    default_resolution = [384, 1280]\n",
    "    mean = np.array([0.485, 0.456, 0.406], np.float32).reshape(1, 1, 3)\n",
    "    std = np.array([0.229, 0.224, 0.225], np.float32).reshape(1, 1, 3)\n",
    "\n",
    "    def __init__(self, opt, split):\n",
    "        super(KITTI, self).__init__()\n",
    "        self.data_dir = os.path.join(opt[\"data_dir\"], 'kitti')\n",
    "        self.img_dir = os.path.join(self.data_dir, 'images', 'trainval')\n",
    "        if opt[\"trainval\"]:\n",
    "            split = 'trainval' if split == 'train' else 'test'\n",
    "            self.img_dir = os.path.join(self.data_dir, 'images', split)\n",
    "            self.annot_path = os.path.join(self.data_dir, 'annotations',\n",
    "                                           'kitti_{}_{}.json').format(opt[\"kitti_split\"], split)\n",
    "        else:\n",
    "            self.annot_path = os.path.join(self.data_dir,\n",
    "                                           'annotations', 'kitti_{}_{}.json').format(opt[\"kitti_split\"], split)\n",
    "        self.max_objs = 50\n",
    "        self.class_name = ['__background__', 'Pedestrian', 'Car', 'Cyclist']\n",
    "        self.cat_ids = {1: 0, 2: 1, 3: 2, 4: -3, 5: -3, 6: -2, 7: -99, 8: -99, 9: -1}\n",
    "\n",
    "        self._data_rng = np.random.RandomState(123)\n",
    "        self._eig_val = np.array([0.2141788, 0.01817699, 0.00341571], dtype=np.float32)\n",
    "        self._eig_vec = np.array([\n",
    "            [-0.58752847, -0.69563484, 0.41340352],\n",
    "            [-0.5832747, 0.00994535, -0.81221408],\n",
    "            [-0.56089297, 0.71832671, 0.41158938]\n",
    "        ], dtype=np.float32)\n",
    "        self.split = split\n",
    "        self.opt = opt\n",
    "        self.alpha_in_degree = False\n",
    "\n",
    "        print('==> initializing kitti {}, {} data.'.format(opt[\"kitti_split\"], split))\n",
    "        self.coco = coco.COCO(self.annot_path)\n",
    "        self.images = self.coco.getImgIds()\n",
    "        self.num_samples = len(self.images)\n",
    "\n",
    "        print('Loaded {} {} samples'.format(split, self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def _to_float(self, x):\n",
    "        return float(\"{:.2f}\".format(x))\n",
    "\n",
    "    def convert_eval_format(self, all_bboxes):\n",
    "        pass\n",
    "\n",
    "    def save_results(self, results, save_dir):\n",
    "        results_dir = os.path.join(save_dir, 'results')\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.mkdir(results_dir)\n",
    "        for img_id in results.keys():\n",
    "            out_path = os.path.join(results_dir, '{:06d}.txt'.format(img_id))\n",
    "            f = open(out_path, 'w')\n",
    "            for cls_ind in results[img_id]:\n",
    "                for j in range(len(results[img_id][cls_ind])):\n",
    "                    class_name = self.class_name[cls_ind]\n",
    "                    f.write('{} 0.0 0'.format(class_name))\n",
    "                    for i in range(len(results[img_id][cls_ind][j])):\n",
    "                        f.write(' {:.2f}'.format(results[img_id][cls_ind][j][i]))\n",
    "                    f.write('\\n')\n",
    "            f.close()\n",
    "\n",
    "    def run_eval(self, results, save_dir):\n",
    "        self.save_results(results, save_dir)\n",
    "        os.system(\n",
    "            './tools/kitti_eval/evaluate_object_3d_offline ' + '/data/kitti/training/label_val ' + '{}/results/'.format(\n",
    "                save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "889ba968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DddDataset(data.Dataset):\n",
    "    def _coco_box_to_bbox(self, box):\n",
    "        bbox = np.array([box[0], box[1], box[0] + box[2], box[1] + box[3]],\n",
    "                        dtype=np.float32)\n",
    "        return bbox\n",
    "\n",
    "    def _convert_alpha(self, alpha):\n",
    "        return math.radians(alpha + 45) if self.alpha_in_degree else alpha\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.images[index]\n",
    "        img_info = self.coco.loadImgs(ids=[img_id])[0]\n",
    "        img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
    "        img = cv2.imread(img_path)\n",
    "        if 'calib' in img_info:\n",
    "            calib = np.array(img_info['calib'], dtype=np.float32)\n",
    "        else:\n",
    "            calib = self.calib\n",
    "\n",
    "        height, width = img.shape[0], img.shape[1]\n",
    "        c = np.array([img.shape[1] / 2., img.shape[0] / 2.])\n",
    "        if self.opt[\"keep_res\"]:\n",
    "            s = np.array([self.opt[\"input_w\"], self.opt[\"input_h\"]], dtype=np.int32)\n",
    "        else:\n",
    "            s = np.array([width, height], dtype=np.int32)\n",
    "\n",
    "        aug = False\n",
    "        if self.split == 'train' and np.random.random() < self.opt[\"aug_ddd\"]:\n",
    "            aug = True\n",
    "            sf = self.opt[\"scale\"]\n",
    "            cf = self.opt[\"shift\"]\n",
    "            s = s * np.clip(np.random.randn() * sf + 1, 1 - sf, 1 + sf)\n",
    "            c[0] += img.shape[1] * np.clip(np.random.randn() * cf, -2 * cf, 2 * cf)\n",
    "            c[1] += img.shape[0] * np.clip(np.random.randn() * cf, -2 * cf, 2 * cf)\n",
    "\n",
    "        trans_input = get_affine_transform(\n",
    "            c, s, 0, [self.opt[\"input_w\"], self.opt[\"input_h\"]])\n",
    "        inp = cv2.warpAffine(img, trans_input,\n",
    "                             (self.opt[\"input_w\"], self.opt[\"input_h\"]),\n",
    "                             flags=cv2.INTER_LINEAR)\n",
    "        inp = (inp.astype(np.float32) / 255.)\n",
    "        inp = (inp - self.mean) / self.std\n",
    "        inp = inp.transpose(2, 0, 1)\n",
    "\n",
    "        num_classes = self.opt[\"num_classes\"]\n",
    "        trans_output = get_affine_transform(\n",
    "            c, s, 0, [self.opt[\"output_w\"], self.opt[\"output_h\"]])\n",
    "\n",
    "        hm = np.zeros((num_classes, self.opt[\"output_h\"], self.opt[\"output_w\"]), dtype=np.float32)\n",
    "        wh = np.zeros((self.max_objs, 2), dtype=np.float32)\n",
    "        reg = np.zeros((self.max_objs, 2), dtype=np.float32)\n",
    "        dep = np.zeros((self.max_objs, 1), dtype=np.float32)\n",
    "        rotbin = np.zeros((self.max_objs, 2), dtype=np.int64)\n",
    "        rotres = np.zeros((self.max_objs, 2), dtype=np.float32)\n",
    "        dim = np.zeros((self.max_objs, 3), dtype=np.float32)\n",
    "        ind = np.zeros((self.max_objs), dtype=np.int64)\n",
    "        reg_mask = np.zeros((self.max_objs), dtype=np.uint8)\n",
    "        rot_mask = np.zeros((self.max_objs), dtype=np.uint8)\n",
    "\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=[img_id])\n",
    "        anns = self.coco.loadAnns(ids=ann_ids)\n",
    "        num_objs = min(len(anns), self.max_objs)\n",
    "        draw_gaussian = draw_msra_gaussian if self.opt[\"mse_loss\"] else draw_umich_gaussian\n",
    "\n",
    "        gt_det = []\n",
    "        for k in range(num_objs):\n",
    "            ann = anns[k]\n",
    "            bbox = self._coco_box_to_bbox(ann['bbox'])\n",
    "            cls_id = int(self.cat_ids[ann['category_id']])\n",
    "            if cls_id <= -99:\n",
    "                continue\n",
    "\n",
    "            bbox[:2] = affine_transform(bbox[:2], trans_output)\n",
    "            bbox[2:] = affine_transform(bbox[2:], trans_output)\n",
    "            bbox[[0, 2]] = np.clip(bbox[[0, 2]], 0, self.opt[\"output_w\"] - 1)\n",
    "            bbox[[1, 3]] = np.clip(bbox[[1, 3]], 0, self.opt[\"output_h\"] - 1)\n",
    "            h, w = bbox[3] - bbox[1], bbox[2] - bbox[0]\n",
    "            if h > 0 and w > 0:\n",
    "                radius = gaussian_radius((h, w))\n",
    "                radius = max(0, int(radius))\n",
    "                ct = np.array([(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2], dtype=np.float32)\n",
    "                ct_int = ct.astype(np.int32)\n",
    "\n",
    "                if cls_id < 0:\n",
    "                    ignore_id = [_ for _ in range(num_classes)] if cls_id == - 1 else [- cls_id - 2]\n",
    "\n",
    "                    if self.opt[\"rect_mask\"]:\n",
    "                        hm[ignore_id, int(bbox[1]): int(bbox[3]) + 1,\n",
    "                        int(bbox[0]): int(bbox[2]) + 1] = 0.9999\n",
    "                    else:\n",
    "                        for cc in ignore_id:\n",
    "                            draw_gaussian(hm[cc], ct, radius)\n",
    "                        hm[ignore_id, ct_int[1], ct_int[0]] = 0.9999\n",
    "                    continue\n",
    "                draw_gaussian(hm[cls_id], ct, radius)\n",
    "\n",
    "                wh[k] = 1. * w, 1. * h\n",
    "                gt_det.append(\n",
    "                    [ct[0], ct[1], 1] + self._alpha_to_8(self._convert_alpha(ann['alpha'])) + [ann['depth']] + (\n",
    "                                np.array(ann['dim']) / 1).tolist() + [cls_id])\n",
    "                if self.opt[\"reg_bbox\"]:\n",
    "                    gt_det[-1] = gt_det[-1][:-1] + [w, h] + [gt_det[-1][-1]]\n",
    "                if 1:\n",
    "                    alpha = self._convert_alpha(ann['alpha'])\n",
    "                    if alpha < np.pi / 6. or alpha > 5 * np.pi / 6.:\n",
    "                        rotbin[k, 0] = 1\n",
    "                        rotres[k, 0] = alpha - (-0.5 * np.pi)\n",
    "                    if alpha > -np.pi / 6. or alpha < -5 * np.pi / 6.:\n",
    "                        rotbin[k, 1] = 1\n",
    "                        rotres[k, 1] = alpha - (0.5 * np.pi)\n",
    "                    dep[k] = ann['depth']\n",
    "                    dim[k] = ann['dim']\n",
    "                    ind[k] = ct_int[1] * self.opt[\"output_w\"] + ct_int[0]\n",
    "                    reg[k] = ct - ct_int\n",
    "                    reg_mask[k] = 1 if not aug else 0\n",
    "                    rot_mask[k] = 1\n",
    "        ret = {'input': inp, 'hm': hm, 'dep': dep, 'dim': dim, 'ind': ind,\n",
    "               'rotbin': rotbin, 'rotres': rotres, 'reg_mask': reg_mask,\n",
    "               'rot_mask': rot_mask}\n",
    "        if self.opt[\"reg_bbox\"]:\n",
    "            ret.update({'wh': wh})\n",
    "        if self.opt[\"reg_offset\"]:\n",
    "            ret.update({'reg': reg})\n",
    "        #         if self.opt[\"debug\"] > 0 or not ('train' in self.split):\n",
    "        #             gt_det = np.array(gt_det, dtype=np.float32) if len(gt_det) > 0 else np.zeros((1, 18), dtype=np.float32)\n",
    "        #             meta = {'c': c, 's': s, 'gt_det': gt_det, 'calib': calib, 'image_path': img_path, 'img_id': img_id}\n",
    "        #             ret['meta'] = meta\n",
    "\n",
    "        return ret\n",
    "\n",
    "    def _alpha_to_8(self, alpha):\n",
    "        ret = [0, 0, 0, 1, 0, 0, 0, 1]\n",
    "        if alpha < np.pi / 6. or alpha > 5 * np.pi / 6.:\n",
    "            r = alpha - (-0.5 * np.pi)\n",
    "            ret[1] = 1\n",
    "            ret[2], ret[3] = np.sin(r), np.cos(r)\n",
    "        if alpha > -np.pi / 6. or alpha < -5 * np.pi / 6.:\n",
    "            r = alpha - (0.5 * np.pi)\n",
    "            ret[5] = 1\n",
    "            ret[6], ret[7] = np.sin(r), np.cos(r)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f84f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataset_info_and_set_heads(opt, dataset):\n",
    "    input_h, input_w = dataset.default_resolution\n",
    "    opt[\"mean\"], opt[\"std\"] = dataset.mean, dataset.std\n",
    "    opt[\"num_classes\"] = dataset.num_classes\n",
    "\n",
    "    # input_h(w): opt.input_h overrides opt.input_res overrides dataset default\n",
    "    opt[\"input_h\"] = input_h\n",
    "    opt[\"input_w\"] = input_w\n",
    "    opt[\"output_h\"] = opt[\"input_h\"] // opt[\"down_ratio\"]\n",
    "    opt[\"output_w\"] = opt[\"input_w\"] // opt[\"down_ratio\"]\n",
    "    opt[\"input_res\"] = max(opt[\"input_h\"], opt[\"input_w\"])\n",
    "    opt[\"output_res\"] = max(opt[\"output_h\"], opt[\"output_w\"])\n",
    "\n",
    "    opt[\"heads\"] = {'hm': opt[\"num_classes\"], 'dep': 1, 'rot': 8, 'dim': 3}\n",
    "    if opt[\"reg_bbox\"]:\n",
    "        opt[\"heads\"].update({'wh': 2})\n",
    "    if opt[\"reg_offset\"]:\n",
    "        opt[\"heads\"].update({'reg': 2})\n",
    "    print('heads', opt[\"heads\"])\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9961d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    class Dataset(KITTI, DddDataset):\n",
    "        pass\n",
    "    return Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60bebc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {}\n",
    "opt[\"head_conv\"] = 256\n",
    "opt[\"num_stacks\"] = 1\n",
    "opt[\"center_thresh\"] = 0.1\n",
    "opt[\"K\"] = 100\n",
    "opt[\"reg_offset\"] = True\n",
    "opt[\"reg_bbox\"] = True\n",
    "opt[\"debug_dir\"] = \"Debug\"\n",
    "opt[\"dataset\"] = \"kitti\"\n",
    "opt[\"std\"] = [0.229, 0.224, 0.225]\n",
    "opt[\"mean\"] = [0.485, 0.456, 0.406]\n",
    "opt[\"num_classes\"] = 3\n",
    "opt[\"debugger_theme\"] = \"white\"\n",
    "opt[\"exp_id\"] = \"default\"\n",
    "opt[\"num_iters\"] = -1\n",
    "opt[\"task\"] = 'ddd'\n",
    "opt[\"device\"] = \"cuda\"\n",
    "opt[\"print_iter\"] = 0\n",
    "opt[\"hide_data_time\"] = True\n",
    "opt[\"lr\"] = 1.25e-4\n",
    "opt[\"lr_step\"] = [45, 60]\n",
    "opt[\"trainval\"] = False\n",
    "opt[\"data_dir\"] = \"data\"\n",
    "opt[\"kitti_split\"] = \"3dop\"\n",
    "opt[\"down_ratio\"] = 4\n",
    "opt[\"batch_size\"] = 2\n",
    "opt[\"num_epochs\"] = 80\n",
    "opt[\"freeze_epoch\"] = 70\n",
    "opt[\"keep_res\"] = False\n",
    "opt[\"nms\"] = False\n",
    "opt[\"no_color_aug\"] = False\n",
    "opt[\"norm_wh\"] = False\n",
    "opt[\"reg_loss\"] = \"l1\"\n",
    "opt[\"scores_thresh\"] = 0.1\n",
    "opt[\"aug_ddd\"] = 0.5\n",
    "opt[\"mse_loss\"] = False\n",
    "opt[\"scale\"] = 0.4\n",
    "opt[\"rect_mask\"] = False\n",
    "opt[\"shift\"] = 0.1\n",
    "opt[\"eval_oracle_dep\"] = False\n",
    "opt[\"dep_weight\"] = 0.1\n",
    "opt[\"dim_weight\"] = 0.2\n",
    "opt[\"rot_weight\"] = 0.1\n",
    "opt[\"wh_weight\"] = 0.1\n",
    "opt[\"off_weight\"] = 0.1\n",
    "opt[\"hm_weight\"] = 0.1\n",
    "opt[\"hyp_weight\"] = 0.01\n",
    "opt[\"center_pixel_weighting\"] = 20\n",
    "opt[\"test\"] = False\n",
    "opt[\"val_intervals\"] = 5\n",
    "opt[\"metric\"] = \"loss\"\n",
    "opt[\"test_scales\"] = [1.0]\n",
    "opt[\"peak_thresh\"] = 0.2\n",
    "opt[\"vis_thresh\"] = 0.3\n",
    "opt[\"debug\"] = 0\n",
    "opt[\"save_dir\"] = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "749689b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heads {'hm': 3, 'dep': 1, 'rot': 8, 'dim': 3, 'wh': 2, 'reg': 2}\n"
     ]
    }
   ],
   "source": [
    "Dataset = get_dataset()\n",
    "opt = update_dataset_info_and_set_heads(opt, Dataset)\n",
    "# opt[\"heads\"] = {'hm': 3}\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4ac4359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_path, optimizer=None, resume=False, \n",
    "               lr=None, lr_step=None):\n",
    "#   state_dict_ = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "#   print('loaded {}'.format(model_path))\n",
    "#   state_dict = {}\n",
    "\n",
    "  start_epoch = 0\n",
    "#   checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "#   print('loaded {}, epoch {}'.format(model_path, checkpoint['epoch']))\n",
    "#   state_dict_ = checkpoint['state_dict']\n",
    "  state_dict_ = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "  state_dict = {}\n",
    "\n",
    "  # convert data_parallal to model\n",
    "  for k in state_dict_:\n",
    "    if k.startswith('module') and not k.startswith('module_list'):\n",
    "      state_dict[k[7:]] = state_dict_[k]\n",
    "    else:\n",
    "      state_dict[k] = state_dict_[k]\n",
    "  model_state_dict = model.state_dict()\n",
    "\n",
    "  # check loaded parameters and created model parameters\n",
    "  msg = 'If you see this, your model does not fully load the ' + \\\n",
    "        'pre-trained weight. Please make sure ' + \\\n",
    "        'you have correctly specified --arch xxx ' + \\\n",
    "        'or set the correct --num_classes for your own dataset.'\n",
    "  for k in state_dict:\n",
    "    if k in model_state_dict:\n",
    "      if state_dict[k].shape != model_state_dict[k].shape:\n",
    "        print('Skip loading parameter {}, required shape{}, '\\\n",
    "              'loaded shape{}. {}'.format(\n",
    "          k, model_state_dict[k].shape, state_dict[k].shape, msg))\n",
    "        state_dict[k] = model_state_dict[k]\n",
    "    else:\n",
    "      print('Drop parameter {}.'.format(k) + msg)\n",
    "  for k in model_state_dict:\n",
    "    if not (k in state_dict):\n",
    "      print('No param {}.'.format(k) + msg)\n",
    "      state_dict[k] = model_state_dict[k]\n",
    "  model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "  # resume optimizer parameters\n",
    "  if optimizer is not None and resume:\n",
    "    if 'optimizer' in checkpoint:\n",
    "      optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "      start_epoch = checkpoint['epoch']\n",
    "      start_lr = lr\n",
    "      for step in lr_step:\n",
    "        if start_epoch >= step:\n",
    "          start_lr *= 0.1\n",
    "      for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = start_lr\n",
    "      print('Resumed optimizer with start lr', start_lr)\n",
    "    else:\n",
    "      print('No optimizer parameters in checkpoint.')\n",
    "  if optimizer is not None:\n",
    "    return model, optimizer, start_epoch\n",
    "  else:\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4189f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DLASeg(opt[\"heads\"],\n",
    "#                final_kernel=1,\n",
    "#                last_level=5,\n",
    "#                head_conv=opt[\"head_conv\"],\n",
    "#                down_ratio=opt[\"down_ratio\"],\n",
    "#                pretrained=True)\n",
    "# model = model.cuda()\n",
    "# model = load_model(model, \"centernet_70.pth\")\n",
    "# optimizer_centernet = torch.optim.Adam(model.parameters(), opt[\"lr\"])\n",
    "\n",
    "# trainer = DddTrainer(opt, model, optimizer)\n",
    "# trainer.set_device(opt[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bd40ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> initializing kitti 3dop, train data.\n",
      "loading annotations into memory...\n",
      "Done (t=0.18s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded train 3712 samples\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "      Dataset(opt, \"train\"),\n",
    "      batch_size=opt[\"batch_size\"],\n",
    "      shuffle=True,\n",
    "      num_workers=4,\n",
    "      pin_memory=True,\n",
    "      drop_last=True)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#       Dataset(opt, 'val'), \n",
    "#       batch_size=1, \n",
    "#       shuffle=False,\n",
    "#       num_workers=1,\n",
    "#       pin_memory=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a84521ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fe4bce62730>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_duq = DUQ(opt).cuda()\n",
    "# model_duq.freeze_feature_extractor()\n",
    "optimizer = torch.optim.Adam(model_duq.parameters(), opt[\"lr\"])\n",
    "criterion = Duq_with_centernet_loss(opt).cuda()\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e1d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1194.8070, hm: 11699.2207, dep: 0.0000, dim: 0.0000, rot: 2.1205, wh: 1.8735, off: 0.0282:   0%"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "hm_losses, dep_losses, dim_losses, rot_losses, wh_losses, off_losses = [], [], [], [], [] ,[]\n",
    "progress = tqdm(range(1, opt['num_epochs']+1))\n",
    "\n",
    "for epoch in progress:\n",
    "    loss_ = []\n",
    "    hm_losses_, dep_losses_, dim_losses_, rot_losses_, wh_losses_, off_losses_ = [], [], [], [], [] ,[]\n",
    "    for batch in train_loader:\n",
    "        for k in batch:\n",
    "            if k!= 'meta':\n",
    "                batch[k] = batch[k].to(device=opt['device'], non_blocking=True)\n",
    "\n",
    "        x = batch['input']\n",
    "#         y = batch['hm']\n",
    "        z, feat = model_duq(x)\n",
    "        loss, loss_stats = criterion((z, feat), batch, model_duq.embeddings)\n",
    "        loss = loss.mean()\n",
    "\n",
    "        hm_l = loss_stats[\"hm_loss\"].cpu().item()\n",
    "        dep_l = loss_stats[\"dep_loss\"].cpu().item()\n",
    "        dim_l = loss_stats[\"dim_loss\"].cpu().item()\n",
    "        rot_l = loss_stats[\"rot_loss\"].cpu().item()\n",
    "        wh_l = loss_stats[\"wh_loss\"].cpu().item()\n",
    "        off_l = loss_stats[\"off_loss\"].cpu().item()\n",
    "\n",
    "        # for visualization\n",
    "        loss_.append(loss.cpu().item())\n",
    "        hm_losses_.append(hm_l)\n",
    "        dep_losses_.append(dep_l)\n",
    "        dim_losses_.append(dim_l)\n",
    "        rot_losses_.append(rot_l)\n",
    "        wh_losses_.append(wh_l)\n",
    "        off_losses_.append(off_l)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model_duq.eval()\n",
    "            model_duq.update_embeddings(x, batch['hm'])\n",
    "            model_duq.update_sigma()\n",
    "\n",
    "        progress.set_description('epoch: %d, loss: %.4f, hm: %.4f, dep: %.4f, dim: %.4f, rot: %.4f, wh: %.4f, off: %.4f' %\\\n",
    "                                 (epoch, loss.item(), hm_l, dep_l, dim_l, rot_l, wh_l, off_l))\n",
    "\n",
    "    loss_mean = np.mean(loss_)\n",
    "    hm_losses_mean = np.mean(hm_losses_)\n",
    "    dep_losses_mean = np.mean(dep_losses_)\n",
    "    dim_losses_mean = np.mean(dim_losses_)\n",
    "    rot_losses_mean = np.mean(rot_losses_)\n",
    "    wh_losses_mean = np.mean(wh_losses_)\n",
    "    off_losses_mean = np.mean(off_losses_)\n",
    "    \n",
    "    losses.append(loss_mean)\n",
    "    hm_losses.append(hm_losses_mean)\n",
    "    dep_losses.append(dep_losses_mean)\n",
    "    dim_losses.append(dim_losses_mean)\n",
    "    rot_losses.append(rot_losses_mean)\n",
    "    wh_losses.append(wh_losses_mean)\n",
    "    off_losses.append(off_losses_mean)\n",
    "\n",
    "    print(f\"EPOCH: {epoch}, LOSS: {loss_mean}\")\n",
    "    torch.save(model_duq.state_dict(), \"certainnet_{}.pth\".format(epoch))\n",
    "    model_duq.update_gamma(epoch)\n",
    "\n",
    "    # freeze base object detector\n",
    "    if epoch == opt[\"freeze_epoch\"]:\n",
    "        model_duq.freeze_feature_extractor()\n",
    "    \n",
    "    # drop lr\n",
    "    if epoch in opt[\"lr_step\"]:\n",
    "        lr = opt[\"lr\"] * (0.1 ** (opt[\"lr_step\"].index(epoch) + 1))\n",
    "        print('Drop LR to', lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_duq.state_dict(), \"certainnet_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b513f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Losses\")\n",
    "plt.savefig(\"losses_duq.png\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c24023",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hm_losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"hm_losses\")\n",
    "plt.savefig(\"hm_losses_duq.png\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d4148",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dep_losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"dep_losses\")\n",
    "plt.savefig(\"dep_losses_duq.png\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dim_losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"dim_losses\")\n",
    "plt.savefig(\"dim_losses_duq.png\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97468894",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rot_losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"rot_losses\")\n",
    "plt.savefig(\"rot_losses_duq.png\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7627d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wh_losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"wh_losses\")\n",
    "plt.savefig(\"wh_losses_duq.png\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40db452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(off_losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"off_losses\")\n",
    "plt.savefig(\"off_losses_duq.png\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed929e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "best = 1e10\n",
    "losses, hm_losses, dep_losses, dim_losses, rot_losses, wh_losses, off_losses = [], [], [], [], [], [], []\n",
    "losses_val, hm_losses_val, dep_losses_val, dim_losses_val, rot_losses_val, wh_losses_val, off_losses_val = [], [], [], [], [], [], []\n",
    "\n",
    "for epoch in tqdm(range(1, opt[\"num_epochs\"] + 1)):\n",
    "    log_dict_train, _ = trainer.train(epoch, train_loader)\n",
    "    losses.append(log_dict_train[\"loss\"])\n",
    "    hm_losses.append(log_dict_train[\"hm_loss\"])\n",
    "    dep_losses.append(log_dict_train[\"dep_loss\"])\n",
    "    dim_losses.append(log_dict_train[\"dim_loss\"])\n",
    "    rot_losses.append(log_dict_train[\"rot_loss\"])\n",
    "    wh_losses.append(log_dict_train[\"wh_loss\"])\n",
    "    off_losses.append(log_dict_train[\"off_loss\"])\n",
    "    print(\"EPOCH: {}, LOSS: {}, HM_LOSS: {}, DEP_LOSS:{}, DIM_LOSS: {}, ROT_LOSS: {}, WH_LOSS: {}, OFF_LOSS: {}\".format(\n",
    "        epoch, log_dict_train[\"loss\"], log_dict_train[\"hm_loss\"], log_dict_train[\"dep_loss\"],\n",
    "        log_dict_train[\"dim_loss\"], log_dict_train[\"rot_loss\"], log_dict_train[\"wh_loss\"],\n",
    "        log_dict_train[\"off_loss\"]))\n",
    "    torch.save(model.state_dict(), \"centernet_{}.pth\".format(epoch))\n",
    "\n",
    "    if opt[\"val_intervals\"] > 0 and epoch % opt[\"val_intervals\"] == 0:\n",
    "        torch.save(model.state_dict(), \"centernet_val_{}.pth\".format(epoch))\n",
    "        with torch.no_grad():\n",
    "            log_dict_val, preds = trainer.val(epoch, val_loader)\n",
    "            losses_val.append(log_dict_val[\"loss\"])\n",
    "            hm_losses_val.append(log_dict_val[\"hm_loss\"])\n",
    "            dep_losses_val.append(log_dict_val[\"dep_loss\"])\n",
    "            dim_losses_val.append(log_dict_val[\"dim_loss\"])\n",
    "            rot_losses_val.append(log_dict_val[\"rot_loss\"])\n",
    "            wh_losses_val.append(log_dict_val[\"wh_loss\"])\n",
    "            off_losses_val.append(log_dict_val[\"off_loss\"])\n",
    "\n",
    "            print(\"VALIDATION EPOCH: {}, LOSS: {}, HM_LOSS: {}, DEP_LOSS:{}, DIM_LOSS: {}, ROT_LOSS: {}, WH_LOSS: {}, OFF_LOSS: {}\".format(\n",
    "                epoch, log_dict_val[\"loss\"], log_dict_val[\"hm_loss\"], log_dict_val[\"dep_loss\"],\n",
    "                log_dict_val[\"dim_loss\"], log_dict_val[\"rot_loss\"], log_dict_val[\"wh_loss\"],\n",
    "                log_dict_val[\"off_loss\"]))\n",
    "            if log_dict_val[opt[\"metric\"]] < best:\n",
    "                best = log_dict_val[opt[\"metric\"]]\n",
    "                torch.save(model.state_dict(), \"centernet_best.pth\")\n",
    "\n",
    "    if epoch in opt[\"lr_step\"]:\n",
    "        lr = opt[\"lr\"] * (0.1 ** (opt[\"lr_step\"].index(epoch) + 1))\n",
    "        print('Drop LR to', lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19439ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"centernet_last.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25532846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
